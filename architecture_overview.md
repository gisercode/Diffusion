# 模型架构概述

`PriSTI` 是一个基于**引导扩散（Guided Diffusion）** 的先进时空数据插补模型。其核心思想是在标准的扩散去噪过程中，利用一个独立的引导网络 (`GWNet`) 从不完整的观测数据中提取强大的时空特征，并将这些特征作为引导信号，指导主扩散模型 (`Guide_diff`) 更精确地恢复缺失的数据。

整个架构可以分为三个核心部分：

1.  **主扩散模型 (`Guide_diff`)**: 负责执行核心的逆向去噪过程。
2.  **引导模块 (`GWNet`)**: 一个独立的时空图神经网络，用于生成高层语义的引导信息。
3.  **核心去噪层 (`NoiseProject`)**: 主扩散模型的基本构建单元，它融合了引导信息，并结合了时间和空间学习能力。

下面是这三个部分的详细介绍。

---

### 1. 主扩散模型 (`Guide_diff`)

这是模型的顶层结构，负责协调整个去噪流程。

*   **输入**:
    *   `x`: 带有噪声的目标数据 `x_t`。
    *   `side_info`: 外部辅助信息（如时间嵌入、节点特征嵌入）。
    *   `diffusion_step`: 当前的扩散时间步 `t`。
    *   `itp_x`: 用于引导的不完整观测数据（来自CDE插值等）。
*   **核心流程**:
    1.  **引导信号生成 (Guidance Path)**:
        *   将 `itp_x` 和 `side_info` 输入到一个独立的 `GWNet` 模块中。
        *   `GWNet` 模块通过其深度时空建模能力，输出一个包含丰富上下文的引导特征 `itp_info`。**这是实现精确引导的关键**。
    2.  **数据预处理 (Denoising Path)**:
        *   将带噪输入 `x` 通过一个 `Conv1d` 投影到模型的内部通道维度。
    3.  **迭代去噪**:
        *   将预处理后的 `x`、`GWNet` 生成的引导特征 `itp_info`、时间步嵌入 `diffusion_emb` 和外部信息 `side_info` 一同送入一系列堆叠的 `NoiseProject` 残差层中进行迭代去噪。
    4.  **输出**:
        *   聚合所有 `NoiseProject` 层的跳跃连接（skip-connection）输出。
        *   通过两个 `Conv1d` 投影层，最终输出预测的噪声 `ε_θ`。

---

### 2. 引导模块 (`GWNet` with `TRConv2D`)

该模块是 `PriSTI` 架构的特色，它极大地增强了模型从不完整数据中学习复杂时空依赖的能力。

*   **架构**: `GWNet` 本质上是一个深度时空图卷积网络，其结构类似于 WaveNet，擅长处理序列数据。
*   **核心特性**:
    1.  **因果卷积 (Causal Convolution)**: 通过巧妙的填充（Padding）实现，确保在处理时间维度时，模型不会“看到”未来的信息。
    2.  **图卷积 (`GraphConvNet`)**: 在每个卷积层之后，都会进行图卷积操作，用于捕捉空间节点之间的依赖关系。它同时支持**静态邻接矩阵**和**自适应邻接矩阵**。
    3.  **张量环卷积 (`TRConv2D`)**: **这是最新的关键升级**。模型中所有的标准 `Conv2d` 层都被替换为 `TRConv2D`，它通过张量分解大幅减少了参数量，同时保持了强大的模型表达能力。`ranks` 参数可在 `config.yaml` 中灵活配置。

---

### 3. 核心去噪层 (`NoiseProject`)

这是构成 `Guide_diff` 主干网络的基本单元。每个 `NoiseProject` 层都通过精巧的设计，将引导信息深度融合到去噪的每一步。

*   **内部流程**:
    1.  **扩散步数嵌入**: 将当前时间步 `t` 转换为 `diffusion_emb`，并注入到上一层的输出 `y` 中。
    2.  **时间学习 (`TemporalLearning`)**:
        *   使用一个基于 Transformer 的注意力机制。
        *   **关键点**: 它执行**交叉注意力**，其中 `Query` 和 `Key` 来自 `GWNet` 生成的引导信号 `itp_info`，而 `Value` 来自带噪数据 `y`。这使得模型能在时间维度上，根据引导信号关注最重要的时间点。
    3.  **空间学习 (`SpatialLearning`)**:
        *   **局部依赖**: 使用 `AdaptiveGCN` 捕捉节点间的局部空间结构。
        *   **全局依赖**: 使用 `Attn_spa`（空间注意力）捕捉全局的空间依赖。同样，这里也执行**交叉注意力**，`itp_info` 作为 `Query` 和 `Key`，`y` 作为 `Value`。
        *   **特征融合**: 将局部和全局特征融合后，通过一个前馈网络（FFN），该网络也已升级为 `TRLinear` 以减少参数。
    4.  **信息融合与输出**:
        *   将空间学习的输出与 `side_info` 融合。
        *   通过门控激活函数（Gated Activation）。
        *   最终输出被分割为两部分：一部分用于下一层的输入（残差连接），另一部分作为跳跃连接（skip-connection）直接送到最终的聚合层。

### 架构流程图

您可以在 [`@/model_flowchart.md`](./model_flowchart.md) 文件中找到详细的、与当前代码完全对应的 Mermaid 流程图。该图表可视化了上述所有组件及其交互方式。